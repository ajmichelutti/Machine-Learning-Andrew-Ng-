{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An optional exercise to download prepare the data used for training the spam classifier. Data for this exercise can be found in the spam assassin public corpus: http://spamassassin.apache.org/old/publiccorpus/.\n",
    "The data consists of email examples either labeled as spam or ham and categorized by detection difficulty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change filenames in directory to make them readable text files.\n",
    "\n",
    "for folder in os.listdir('/Users/user/Spam_Emails'):\n",
    "    if 'ham' in folder or 'spam' in folder:\n",
    "        for filename in os.listdir(folder):\n",
    "            if not filename.endswith(\".txt\"):\n",
    "                os.rename(folder + '/' + filename, folder + '/' + filename + '.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through folders containing the word ham(non spam emails) storing email contents in ham_list variable.\n",
    "\n",
    "ham_list = []\n",
    "for folder in os.listdir('/Users/user/Spam_Emails'):\n",
    "    if 'ham' in folder:\n",
    "        for filename in os.listdir(folder):\n",
    "            if len(filename) > 10:\n",
    "                with open(folder + '/' + filename, 'r', errors='ignore') as email:\n",
    "                    contents=email.read()\n",
    "                    ham_list.append(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Iterate through folders containing the word spam(spam emails) storing email contents in spam_list variable.\n",
    "\n",
    "spam_list = []\n",
    "for folder in os.listdir('/Users/user/Spam_Emails'):\n",
    "    if 'spam' in folder:\n",
    "        for filename in os.listdir(folder):\n",
    "            if len(filename) > 10:\n",
    "                with open(folder + '/' + filename, 'r', errors='ignore') as email:\n",
    "                    contents=email.read()\n",
    "                    spam_list.append(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ham_array = np.array(ham_list)\n",
    "spam_array = np.array(spam_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert to dataframe and add label to indicate class membership.\n",
    "\n",
    "ham_data = pd.DataFrame({'email': ham_array, 'label' : 0})\n",
    "spam_data = pd.DataFrame({'email': spam_array, 'label' : 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatenate ham/spam data and shuffle to randomize order.\n",
    "\n",
    "data = pd.concat([ham_data, spam_data])\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data = data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From submit27@desertmail.com  Wed Jul 24 02:48...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Return-Path: &lt;Online#3.20502.53-KAuEgBlRpyKZc9...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From qtopic+admin@quicktopic.com  Sun Oct  6 2...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Received: from b.smtp-out.sonic.net (b.smtp-ou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Received: from hq.pro-ns.net (localhost [127.0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               email  label\n",
       "0  From submit27@desertmail.com  Wed Jul 24 02:48...      1\n",
       "1  Return-Path: <Online#3.20502.53-KAuEgBlRpyKZc9...      0\n",
       "2  From qtopic+admin@quicktopic.com  Sun Oct  6 2...      0\n",
       "3  Received: from b.smtp-out.sonic.net (b.smtp-ou...      1\n",
       "4  Received: from hq.pro-ns.net (localhost [127.0...      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.porter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The vocab list is a list of predetermined words to use as features in the model's predictions.\n",
    "\n",
    "vocab = pd.read_table('/Users/user/Spam_Emails', header=None)\n",
    "vocab_list = vocab.drop([0], axis = 1).values\n",
    "vocab_list = vocab_list.ravel().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_email(email):\n",
    "    # reads through the contents of an email and returns a list of numbers \n",
    "    # signifying at what index each word occurs in the vocab list. (To be used as a feature vector).\n",
    "    \n",
    "    # Simplifies words down to their root form. Spamilicious -> spam.\n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    # Converts links, numbers, email handles, and dollar signs to simple one word features.\n",
    "    email = email[email.find('\\n\\n'):].lower()\n",
    "    email = re.sub(r'(http|https)://[^\\s]*', 'httpaddr', email)\n",
    "    email = re.sub('[0-9]+.*', 'number', email)\n",
    "    email = re.sub(r'[^\\s]+@[^\\s]+', 'emailaddr', email)\n",
    "    email = re.sub(r'[$]+', 'dollar', email)\n",
    "    \n",
    "    # Tokenize email, stem words, and remove non alphanumeric characters.\n",
    "    email = nltk.word_tokenize(email)\n",
    "    email = [re.sub(r'[^a-zA-Z0-9]', '', i) for i in email]\n",
    "    email = [stemmer.stem(word) for word in email if len(word) >= 1]\n",
    "    word_indices = [vocab_list.index(i) for i in email if i in vocab_list]\n",
    "    \n",
    "    return word_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def email_features(word_indices):\n",
    "    # Converts the word index arrays into a sparse array of of zeros and ones denoting \n",
    "    # whether or not a word in the vocab list appeared in the email.\n",
    "    \n",
    "    feature = np.zeros([len(vocab_list), 1])\n",
    "    feature[word_indices] = 1\n",
    "    \n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply functions to dataframe.\n",
    "\n",
    "data['word_indices'] = data.email.apply(process_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['features'] = data.word_indices.apply(email_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['features'] = data.features.apply(np.ravel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feats = data['features'].apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1889</th>\n",
       "      <th>1890</th>\n",
       "      <th>1891</th>\n",
       "      <th>1892</th>\n",
       "      <th>1893</th>\n",
       "      <th>1894</th>\n",
       "      <th>1895</th>\n",
       "      <th>1896</th>\n",
       "      <th>1897</th>\n",
       "      <th>1898</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1899 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2     3     4     5     6     7     8     9     ...   1889  \\\n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    0.0   \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    0.0   \n",
       "2   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0  ...    0.0   \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    0.0   \n",
       "4   0.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0  ...    0.0   \n",
       "\n",
       "   1890  1891  1892  1893  1894  1895  1896  1897  1898  \n",
       "0   0.0   0.0   1.0   0.0   1.0   0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0   1.0   0.0   1.0   0.0   0.0   0.0   0.0  \n",
       "3   0.0   0.0   1.0   0.0   1.0   0.0   0.0   0.0   0.0  \n",
       "4   0.0   0.0   1.0   0.0   1.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 1899 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.label\n",
    "y = y.values.reshape(len(y),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split data into training and testing sets.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and fit classifier.\n",
    "\n",
    "clf = SVC(kernel='linear', C=1)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99181243021957577"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spam detection accuracy on test set.\n",
    "\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# K-fold cross validation performed on the training set.\n",
    "\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.99007444,  0.98573201,  0.98945409,  0.98635236,  0.98819876])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Results. \n",
    "\n",
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
